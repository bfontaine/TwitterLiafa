29/03/2012
----------

1. On prend une URL (« spread »), et on récupère tous les tweets qui citent cette URL. Ensuite, on récupère tous les auteurs de ces tweets, et tous leurs tweets.
2. On analyse les interactions (retweets et mentions) entre utilisateurs *avant* le spread (i.e. avant le tweet qui cite l'URL donnée).
3. On représente l'activité autour de cette URL avec les retweets qui la mentionnent. On remarque des graphes en étoile avec un utilisateur qui cite cette URL, et un certain nombre qui le retweet. Une bonne moitié du graphe représente des utilisateurs isolés qui ont tweeté l'URL.
4. On collecte les informations de suivi (following/followers) *après* le spread, et on essaye de déterminer l'impact des tweets « originels » (i.e. les tweets qui ont déclenchés des retweets) sur les nouvelles relations (ma tâche).    Par exemple, soit trois utilisateurs *A*, *B*, *C*. *A* suit *B* qui suit *C*. *B* retweet *C*, *puis* *A* retweet *C*. On peut supposer que *A* a retweeté *C* suite au retweet de *B*. Ensuite, si *A* se met à suivre *C*, on pourra supposer que c'est suite au retweet via *B*.

- G0: Premier graphe (avant/pendant le spread)
- Gf: Graph des followers

05/04/2012
----------

- Objectif: récupérer le graphe des followers et essayer de voir le lien entre les "follows" et les RT. Cf `followers/ids`, `friends/ids`, `users/lookup`.
- Faire fichier de stats avec pour chaque graphe le nb d' users/liens
- Faire un cache id/nom/followers/follows global
- Comparer graphe des followers avec G0 (regarder l'intersection des graphes, recouvrement des liens, etc)
- Pour chaque graphe, calculer pourcentage de recouvrement (liens communs) entre Gf et G0.
- Garder l'ordre de la liste followers/follows (ordre d'ancienneté) -> attribut de lien
- attributs de noeuds : date d'extraction des followers/follows

16/04/2012
----------

- Pour chaque graphe, récupérer nb noeuds / nb liens / 2+ grands degrés

17/04/2012
----------

- Pour chaque paire G0/Gf, calculer le pourcentage de recouvrement (par rapport
  à G0 __et__ Gf)

23/04/2012
----------

- Générer un .csv avec les colonnes suivantes:
    - numéro du graph                                         (0)
    - nombre de noeuds                                        (1)
    [- valeur du plus haut degré de Gf                         (d)]
    - nombre de liens dans G0                                 (2)
    - nombre de liens dans Gf                                 (3)
    - nombre de liens dans G0&Gf (intersection)               (4)
    - ((4) / (2))                                             (5)
    - ((4) / (3))                                             (6)
    - (6) en supprimant les noeuds inactifs de Gf (≥5 tweets) (7)
    - idem que 7, mais avec 10 tweets                         (8)

- Générer les graphs combinés G0+Gf (ajouter les attributs `G0` (est dans G0),
  `Gf` (idem), et `G0Gf` (est dans les deux)).

- Faire un tableau à 2 dimensions, avec pour chaque paire de graphes,
  l'intersection des noeuds de chacun (but: trouver les utilisateurs qui
  reviennent souvent) -> on peut faire un tableau juste pour voir les tailles,
  en utilisant des couleurs.

30/04/2012
----------

- Gx = G0&RT (les RT issus de gens qui suivent l'auteur du tweet d'origine)
- Il faut trouver les liens Gf&RT&~G0, i.e. les liens avec A et B où A n'a pas
  interagi avec B (G0), mais A suit B (Gf) et A a RT B
- Voir dans le JSON les personnes qui ont été RTées
- G'f = { u→v dans Gf tq il existe x→v dans GRT }
- GRT = graph des RT
- I = G0&Gf, intersection de G0 et Gf
- I' = G0&G'f, intersection de G0 et G'f
- `XXX_interactions.json` : liste des tweets qui mentionnent l'URL (tweets+RT)
- Voir avec `XXX_interactions.json` les gens qui ont tweeté l'URL après que l'un
  de leurs followings ai tweeté l'URL.
- TODO créer le GRT avec `XXX_interactions.json`, et calculer les intersections
  GRT&G0, GRT&Gf, et GRT&G0&Gf (avec à chaque fois le pourcentage de
  recouvrement par rapport à GRT). Mettre les résultats dans un CSV avec les
  autres, + créer des courbes pour la visualisation.
- Écrire le rapport de stage/présentation la semaine du 14-20
- RDV 11h 7 mai

07/05/2012
----------

- Mettre l'URL du spread dans le CSV (ou domaine + le texte du premier tweet)
- Pour chaque RT par ordre chronologique (A a RTé B), voir: 1) si A a interragi
  avec B (si A->B est dans G0), 2) si un voisin de A (lien sortant dans G0) a
  déjà RTé B avant.
- Refaire la même chose en changeant G0 par Gf.
- Exemple de sortie: GDF avec un attribut sur les liens correspondant à comment
  ce RT est expliqué
- Sortir un CSV avec pour chaque graph combien de % de RTs sont expliqués par un
  voisin dans G0, par un voisin dans Gf (% par rapport au nb de RT total)
- "soutenance" le 22 mai à 15h30 (sera peut-être avancé à 14h): faire un
  document et une présentation (~15min): présenter Twitter, comment ça marche,
  quelques aspects techniques (mais pas trop), l'API Twitter, les techniques
  utilisées (Ruby, etc).

14/05/2012
----------

- La recherche d'explications sur G0, voisins de G0, Gf et voisins de Gf doit
  être indépendante à chaque fois (ex: ça peut être expliqué par G0 **et** par
  un voisinage dans G0).

